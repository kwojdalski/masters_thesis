

# Machine Learning

In this chapter, the term **machine learning** and its subfields are explained.
The discussion also encompasses potential applications for trading financial
instruments.

As the field evolves, numerous definitions of machine learning emerge from
various sources. In this subchapter, the author has selected definitions that
accurately capture the essence of the discipline.

What is machine learning? The most widely accepted definitions are as follows:

* "Field of study that gives computers the ability to learn without being
explicitly programmed." - Arthur Samuel, a pioneer in machine learning and
computer gaming @Samuel1959
* "A computer program is said to learn from experience $E$ with respect to some
class of tasks $T$ and performance measure $P$, if its performance at tasks in
$T$, as measured by $P$, improves with experience $E$." - Tom Mitchell, a
computer scientist and E. Fredkin University Professor at Carnegie Mellon
University (CMU) @Mitchell1997

The latter is particularly regarded as an elegant and modern definition. Less
formal, but equally relevant observations come from textbook authors in the
discipline:

* "Pattern recognition has its origins in engineering, whereas machine learning
grew out of computer science. However, these activities can be viewed as two
facets of the same field…" - Christopher Bishop
* "One of the most interesting features of machine learning is that it lies on
the boundary of several different academic disciplines, principally computer
science, statistics, mathematics, and engineering. …machine learning is usually
studied as part of artificial intelligence, which puts it firmly into computer
science …understanding why these algorithms work requires a certain amount of
statistical and mathematical sophistication that is often missing from computer
science undergraduates." - Stephen Marsland @Marsland2009

![Data Science Graph](../../figures/data_science.png){width=400px; height=400px}

Despite numerous concepts and perspectives on what machine learning entails, the
general objective remains consistent: Machine learning involves building models
that sufficiently resemble reality, are optimal with respect to a value function,
and can subsequently be utilized for predictions on new data.

## Why is machine learning important?

Machine learning facilitates solving problems that are difficult or impossible to
address deterministically @Jason2013. Variables may be missing or observed values
may contain embedded errors. Traditional models are often susceptible to being
under- or overdetermined. They may fail to generalize adequately or may be
excessively general. An appropriate machine learning model should provide an
approximate solution incorporating only relevant components.

## Classification of machine learning algorithms

In machine learning (ML), tasks are categorized based on how learning/feedback
($P$) is received and/or the type of problem they address. The following
categories can be distinguished:

* Supervised Learning - the complete set $(Y_t;X_{t, 1}, ..., X_{t,n})$
is available. The objective is to model the target variable $Y_t$ using a subset
of $X_t$ variables, i.e., find a functional relationship $Y_t = f(\mathbb{X_t})$
between input and output variables that minimizes a predefined loss function
$g(f(\mathbb{X}_t);Y_t)$. The structural form of this relationship is constrained
by the class of functions considered. For example, assuming a linear relationship
between input and output variables with a square loss function, the problem
becomes:
  $$\min_{b_1\dots b_n}\mathbb{E}[(Y_t-(b_1X_{t,1}+\dots+b_nX_{t,n}))^2]$$

    The estimation method above is known as the least squares method for linear
    regression. Despite its simplicity, it often yields sufficient results. Other
    popular supervised learning methods include:
    + K-nearest neighbors, Neural Networks
    + SVM - Support Vector Machines
    + Random Forests

* Unsupervised learning - this category deals exclusively with the $\mathbb{X_t}$
set. The goal is to identify patterns within the dataset and categorize
observations. The most prevalent methods include:
    + Clustering - based on finding groups of instances that are as similar as
    possible to observations within the same group while being as different as
    possible from observations in other groups
    + Feature extraction - this subcategory comprises methods for extracting
    relevant variables from a set $\mathbb{X}_t$. Often, a subset of a dataset
    can contain a similar amount of information as the original while reducing
    dimensionality, thereby enhancing computational efficiency and improving the
    model in accordance with Occam's Razor.
    + Anomaly detection - this approach aids in identifying outlier observations
    that warrant careful investigation. Variables may require transformation or
    invalid observations may need removal.

* Reinforcement Learning - this is perhaps the most intuitive category of ML in
terms of what is commonly associated with artificial intelligence. According to
@Silver2017, it incorporates influences from engineering, economics, mathematics,
neuroscience, psychology, and computer science. Reinforcement learning algorithms
maximize long-term cumulative rewards and **interact with the environment**,
making them suitable for non-stationary problems.

    The two distinctive features of reinforcement learning algorithms are
    trial-and-error and delayed rewards, meaning this type of ML evaluates
    actions rather than providing definitive instructions. This distinguishes
    reinforcement learning from supervised learning and constitutes one reason
    why it is considered a distinct subfield in ML.

    Moreover, it does not rely on a training set of labeled examples. In
    supervised learning, each observation specifies precisely what an algorithm
    should do. For instance, if blue balls according to the model should be in a
    blue basket, they will invariably end up there.

    The goal of supervised learning is to generalize effectively from training
    data so that the formula works for test data as well. While important and
    extensively researched, this approach is insufficient when interaction
    between an agent and an environment occurs. In such scenarios, an agent must
    learn from its own actions, sense states, and accumulate experience.

    Reinforcement learning must also be distinguished from unsupervised learning.
    Unsupervised learning focuses on identifying structures not explicitly given
    in collections of unlabeled datasets. While this sounds similar, it differs
    fundamentally from RL, where the objective is to maximize the sum of reward
    signals. Finding data patterns may be useful (as noted in the section on
    unsupervised learning), but it does not address a reinforcement learning
    problem. Hence, the approach analyzed in this thesis should be considered a
    separate paradigm.

    The only feedback an agent receives is a scalar reward. Its objective is to
    maximize a long-run value function comprising summed (discounted) rewards in
    subsequent states. The agent aims to learn through trial-and-error which
    actions maximize long-run rewards. The environment changes stochastically and
    sometimes interacts with the agent. The agent must select a policy that
    optimizes the rewards received. The design must account for this by adjusting
    the agent to avoid purely greedy behavior, i.e., it should explore new
    actions rather than exclusively exploiting existing optimal (possibly
    suboptimal) solutions.
