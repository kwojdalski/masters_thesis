---
output: html_document
editor_options: 
  chunk_output_type: console
---

In this chapter term **machine learning** and its subfields are explained. Discussion also contains possible applications
for trading financial instruments.

# Machine Learning

  As the field evolves, there are many definitions of machine learning sources provide. In this subchapter, the author has arbitrarly selected definitions that accurately captures the spirit of the discipline.
What is machine learning then? The most accepted and widely used definitions are as follows:

* "Field of study that gives computers the ability to learn without being explicitly programmed." - Arthur Samuel, a pioneer in machine learning and computer gaming @Samuel1959
* "A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, 
if its performance at tasks in $T$, as measured by $P$, improves with experience $E$." - Tom Mitchell, a computer scientist and E. Fredkin University Professor at the Carnegie Mellon University (CMU) @Mitchell1997

Especially the latter is considered as an elegant and modern definition. Less formal, but also relevant remarks, comes from two authors of textbooks from the discipline:

* "Pattern recognition has its origins in engineering, whereas machine learning grew out of computer science. However, these activities can be viewed as two facets of the same field…" - Christopher Bishop
* "One of the most interesting features of machine learning is that it lies on the boundary of several different academic disciplines, principally computer science, statistics, mathematics, and engineering. …machine learning is usually studied as part of artificial intelligence, which puts it firmly into computer science …understanding why these algorithms work requires a certain amount of statistical and mathematical sophistication that is often missing from computer science undergraduates." - Stephen Marsland @Marsland2009

![Data Science Graph](../img/data_science.png){width=400px; height=400px}

Despite many more concepts, ideas, and comments as to what exactly machine learning is,  the general goal is the same:
Machine learning is about building such models that resemble the reality to a sufficient extent, are optimal in terms of a value function and can be later used for predictions on new data.

### Why is machine learning important?

Machine learning helps in solving problems that are difficult or even impossible to solve in a determinisic way. @Jason2013
Sometimes variables can be missing or observed values can contain an embedded error. Traditional models are often prone to be
under- or overdetemined. They might not generalize well or are too general. An appropriate machine learning model should contain approximate solution containing only relevant parts.

### Classification of machine learning algorithms

In machine learning (ML), tasks are classified into broader categories based on how learning/feedback ($P$) is received and/or what kind of problem they solve. One can distinct the following ones:

* Supervised Learning - the whole set $(Y_t;X_{t, 1}, ..., X_{t,n})$
is available. The goal is to model the special variable $Y_t$ using a subset
of $X_t$ variables, i.e. find a functional relationship $Y_t = f(\mathbb{X_t})$ between the input variables and the output variables which
minimizes a predefined loss function $g(f(\mathbb{X}_t);Yt)$. The structural form of this
relationship is constrained by the class of functions considered. For example
we can assume that there is a linear relationship between input and output
variables and a square loss function, then the problem becomes:
  $$\min_{b1\dots bn}\mathbb{E[}(Y_t-(b_1X_{t,1}+\dots+b_nX_{t,n}))^2]$$

    The utilized estimation method above is called least squares method for linear regression. Even though it is considered a simple one, it sometimes provides sufficient results. Other popular methods for supervised learning are:
    + K-nearest neighboors, Neural Networks, 
    + SVM - Support Vector Machines,
    + Random Forests

* Unsupervised learning - it is the category that deals with only $\mathbb{X_t}$ set. In other words, The goal is to find patterns among the dataset and categorize observations. The most popular methods are:
    + Clustering - based on finding groups of instances which are similar as possible to observations from the same groups while as different as possible to observations from other ones
    + Feature extraction - this subcategory of unsupervised learning consists of methods for 
 extracting relevant variables from a set of variables $\mathbb{X}_t$. Often, a subset of a dataset can
 contain a similar amount of information as the original one while reducing dimensionality so that a model computation is much
 faster and efficient. improves the model in Occam's Razor sense.
    + Anomaly detection - this type helps in identification of observations that are outliers and should be carefully investigated.
 Sometimes the whole variable needs to be transformed or spotted observations must be removed due to their invalidity.
* Reinforcement Learning - it is probably the most intuitive category of ML in terms of what people implicitly believe to be artificial intelligence. According to @Silver2017, it captures influences from disciplines such as engineering, economics, mathematics, neuroscience, psychology and computer science. Algorithms in reinforcement learning maximize long-term cumulated reward and **interacts with the environment**, i.e. are convenient when a problem is 
not stationary. 

    The two most specific features of reinforcement learning algorithms are trial-and-error and delayed rewards what means 
    that this type of ML uses training information to evaluate the actions rather than instructs by giving definitive 
    actions. This is what distinguishes reinforcement learning from supervised learning and is one 
    of the reasons why it is     considered as a subfield in ML. 
    Moreover, it does not base on a training set of labeled examples. In SL, each observation is 
    strictly specified as to what an     algorithm should do. For instance if blue balls according 
    to the model should be in blue basket, 
    they will always end up there.     
    Supervised learning goal is to generalize well on the training data so that the formula works 
    also for the test data. It is     important and the most researched area of ML nowadays, 
    however it is not enough when interaction between an agent and an     
    environment take place. In such problems an agent should learn from its own actions, sense states,
    and gain experience.

     Reinforcement learning need to be distincted from unsupervised learning as well. 
     UL is focused on finding structures not explicitly given by collections of unlabeled datasets. 
     It sounds similar, but it is far from RL, where the whole idea is to maximize sum of reward signals.
     Finding data patterns might be useful (as stated in the bullet point about unsupervised learning),
     but it does not solve a RL problem. Hence, the approach analyzed in the thesis should be 
     considered as a next paradigm, seperated      paradigm.
       The only feedback an agent receives is a scalar reward. The goal of it is
     to maximize long-run value function which consists of summed up (discounted) rewards in subsequent states.
     The goal of the agent is to learn by trial-and-error which actions maximize his long-run rewards. 
     The environment changes stochastically and  in some cases interacts with the agent. The agent must choose such a policy that      optimizes amount of rewards it receives.
     The design must capture this fact by adjusting the agent so that it does not act greedily, i.e. it should explore new 
     actions instead of exploiting existing optimal (possibly suboptimal) solutions.

